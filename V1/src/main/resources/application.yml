spring:
  application:
    name: ${APP_NAME:kafka-message-processor}
  
  cloud:
    vault:
      host: ${VAULT_HOST}
      port: ${VAULT_PORT:8200}
      scheme: ${VAULT_SCHEME:https}
      authentication: ${VAULT_AUTH_METHOD:*****}
      token: ${VAULT_T}
      kv:
        enabled: true
        backend: ${VAULT_B:*****}
        default-context: ${VAULT_CONTEXT:*****}
      fail-fast: true
      connection-timeout: ${VAULT_CONN_TIMEOUT:5000}
      read-timeout: ${VAULT_READ_TIMEOUT:15000}

vault:
  S:
    kafka-path: ${VAULT_K_PATH:*****}

  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS}
    consumer:
      group-id: ${KAFKA_CONSUMER_GROUP:kafka-message-processor-group}
      max-poll-records: ${KAFKA_MAX_POLL_RECORDS:500}
      heartbeat-interval: ${KAFKA_HEARTBEAT_INTERVAL:3000}
      session-timeout-ms: ${KAFKA_SESSION_TIMEOUT:30000}
      max-poll-interval-ms: ${KAFKA_MAX_POLL_INTERVAL:300000}
      auto-offset-reset: ${KAFKA_AUTO_OFFSET_RESET:earliest}
      enable:
        auto:
          commit: false
      partition:
        assignment:
          strategy: ${KAFKA_PARTITION_STRATEGY:org.apache.kafka.clients.consumer.RoundRobinAssignor}
      metadata:
        max:
          age:
            ms: ${KAFKA_METADATA_MAX_AGE:30000}
    listener:
      missing-topics-fatal: false
      concurrency: ${KAFKA_CONCURRENCY:30}  # Total partitions / consumers per DC
      ack-mode: MANUAL
      shutdown-timeout: ${KAFKA_SHUTDOWN_TIMEOUT:120000}

  datasource:
    url: ${DB_URL:*****}
    driverClassName: ${DB_DRIVER:*****}
    U: ${DB_U:*****}
    P: ${DB_P:*****}
  jpa:
    database-platform: ${JPA_DIALECT:org.hibernate.dialect.H2Dialect}
    hibernate:
      ddl-auto: ${JPA_DDL_AUTO:update}
    show-sql: ${JPA_SHOW_SQL:false}
    properties:
      hibernate:
        format_sql: ${JPA_FORMAT_SQL:true}
  h2:
    console:
      enabled: ${H2_CONSOLE_ENABLED:false}
      path: ${H2_CONSOLE_PATH:/h2-console}

kafka:
  topic:
    json:
      name: ${KAFKA_JSON_TOPIC_NAME}
      partitions: ${KAFKA_PARTITIONS:60}
      consumers-per-dc: ${KAFKA_CONSUMERS_PER_DC:2}
      retry-interval-ms: ${KAFKA_JSON_RETRY_INTERVAL:30000}
      session-timeout-ms: ${KAFKA_JSON_SESSION_TIMEOUT:60000}
      heartbeat-interval-ms: ${KAFKA_JSON_HEARTBEAT_INTERVAL:20000}
    avro:
      name: ${KAFKA_AVRO_TOPIC_NAME}
      partitions: ${KAFKA_PARTITIONS:60}
      consumers-per-dc: ${KAFKA_CONSUMERS_PER_DC:2}
      retry-interval-ms: ${KAFKA_AVRO_RETRY_INTERVAL:30000}
      session-timeout-ms: ${KAFKA_AVRO_SESSION_TIMEOUT:60000}
      heartbeat-interval-ms: ${KAFKA_AVRO_HEARTBEAT_INTERVAL:20000}
    health-check:
      enabled: ${KAFKA_HEALTH_CHECK_ENABLED:true}
      interval: ${KAFKA_HEALTH_CHECK_INTERVAL:30000}
    route-away:
      check-interval: ${KAFKA_ROUTE_AWAY_CHECK_INTERVAL:30000}
      shutdown-timeout: ${KAFKA_ROUTE_AWAY_SHUTDOWN_TIMEOUT:120000}

app:
  processing:
    message-tracking:
      enabled: ${MESSAGE_TRACKING_ENABLED:true}
    metrics:
      reporting-interval: ${METRICS_REPORTING_INTERVAL:30000}

logging:
  level:
    root: INFO
    org.apache.kafka: INFO
    org.springframework.kafka: INFO
    com.example.kafkaprocessor: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/kafka-processor.log
    max-size: 10MB
    max-history: 7